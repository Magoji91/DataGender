library(readxl)
data18 <- read_excel("C:/Users/smsanda/Pictures/data18.xlsx")
View(data18)

data<-data18

library(dplyr)
library(moments)

head(data) # Print the first few, or last few, lines of a mdm object
str(data) #check the variables / Get a summary of an object’s structure
summary(data) #Get more detailed information out a model.
dim(data) #check dimesions ( number of row & columns) in data set
ls(data) # List all variables in the environment.
table(is.na(data)) # See counts of missing values
colSums(is.na(data)) # missing value in data exploration stages.
unique(data) #See unique values.
pairs(data)

#You can use the loglm( ) function in the MASS package to produce log-linear models. 
library(MASS)
attach(data)

A<-data$gender # Access the values
table(A)
table(A, useNA = "ifany")
summary(A)
sd(A) #grau de variação de um conjunto de dados
var(A) #indicador de variabilidade dos dados X Graus de liberdade é a diferença entre a dimensão da amostra (n) e a quantidade de parâmetros a serem avaliados na população
CVA=(sd(A)/mean(A))*100 #indica a quantidade de variação de um conjunto de dados em relação a média
print(CVA)
SKA = (3*(mean(A) - median(A))/(sd(A))) #Sk≈0: dados simétricos. Tanto a cauda do lado direito quanto a do lado esquerdo da função densidade de probabilidade são iguais // Sk<0: assimetria negativa. A cauda do lado esquerdo da função densidade de probabilidade é maior que a do lado direito. // Sk>0: assimetria positiva. A cauda do lado direito da função densidade de probabilidade é maior que a do lado esquerdo.
print(SK)
kurtosis(A0 #Ck≈0: Distribuição normal. Chamada de Curtose Mesocúrtica. // Ck<0: Cauda mais leve que a normal. Para um coeficiente de Curtose negativo, tem-se uma Curtose Platicúrtica. // Ck>0: Cauda mais pesada que a normal. Para um coeficiente de Curtose positivo, tem-se uma Curtose Leptocúrtica.


B<-data$birthyear
table(B)
table(B, useNA = "ifany")
summary(B)
sd(B)
var(B)
CVB=(sd(B)/mean(B))*100
print(CVB)
SKB = (3*(mean(B) - median(B))/(sd(B)))
print(SKB)
kurtosis(B)

C<-data$country
table(C)
table(C, useNA = "ifany")
summary(C)
sd(C)
var(C)
CVC=(sd(C)/mean(C))*100
print(CVC)
SKC = (3*(mean(C) - median(C))/(sd(C)))
print(SKC)
kurtosis(D)

D<-data$education
table(D)
table(D, useNA = "ifany")
summary(D)
sd(D)
var(D)
CVD=(sd(D)/mean(D))*100
print(CVD)
SKD = (3*(mean(D) - median(D))/(sd(D)))
print(SKD)
kurtosis(D)

#PLOTS

plot(data$gender)
barplot(data$gender)
plot(table(data$gender))
barplot(table(data$gender))

plot(data$education)
barplot(data$education)
plot(table(data$education))
barplot(table(data$education))
 
plot(data$country)
barplot(data$country)
plot(table(data$country))
barplot(table(data$country))
 
plot(data$birthyear)
barplot(data$birthyear)
plot(table(data$birthyear))
barplot(table(data$birthyear))

#The creation of frequency and contingency tables from categorical variables, along with tests of independence, measures of association, and methods for graphically displaying results.

Generating Frequency Tables
R provides many methods for creating frequency and contingency tables. Three are described below. In the following examples, assume that A, B, and C represent categorical variables.  

mytable <- xtabs(~A+B+C+D, data=data) 
hist(mytable)
summary(mytable) # chi-square test of indepedence

loglm(~A+B+C+D, mytable) #Mutual Independence: A, B, C and D are pairwise independent.

#P=1 - Significa uma correlação perfeita positiva entre as duas variáveis.
#P=-1 - Significa uma correlação negativa perfeita entre as duas variáveis - Isto é, se uma aumenta, a outra sempre diminui.
#P=0  - Significa que as duas variáveis não dependem linearmente uma da outra. No entanto, pode existir uma dependência não linear. Assim, o resultado deve ser investigado por outros meios.

#Observação sobre os Resultados da Covariância
#Quando covariância é positiva, as duas variáveis analisadas tendem a variar na mesma direção; portanto, se aumenta uma a outra tende a aumentar, ou se uma cai a outra tende a diminuir também. Logo covariância positiva indica que as duas variáveis caminham juntas mediante variações que ocorrerem.
#Quando houver covariância negativa, neste caso há duas variáveis que tendem a variar em direções opostas; ou seja, se há aumento em uma haverá diminuição na outra, ou se uma diminui a outra tende a aumentar. concluímos que a covariância negativa afirma categoricamente que há oposição com relação aos movimentos das variáveis.
#Quanto mais próxima de zero for a covariância obtida aplicando-se a fórmula, menor é a possibilidade de encontrar um comportamento de interdependência linear entre as variáveis.


#Subsetting data
# Select only the variables that you are interested in.

#Desempenho dos homens nas questões de MATEMÁTICA
library(dplyr)

genmascmat<-select(filter(data, consent == 1, gender == 1),c(I, II, III, IV, V))
M1<-table(genmascmat$I ==1)
M2<-table(genmascmat$II ==1)
M3<-table(genmascmat$III ==1)
M4<-table(genmascmat$IV ==1)
M5<-table(genmascmat$V ==1)

cbind(M1, M2, M3, M4, M5)
mm<-rowSums(cbind(M1, M2, M3, M4, M5), na.rm=TRUE)


#Desempenho das mulheres nas questões de MATEMÁTICA
genfemat<-select(filter(data, consent == 1, gender == 2),c(I, II, III, IV, V))
F1<-table(genfemat$I ==1)
F2<-table(genfemat$II ==1)
F3<-table(genfemat$III ==1)
F4<-table(genfemat$IV ==1)
F5<-table(genfemat$V ==1)

cbind(F1, F2, F3, F4, F5)
mf<-rowSums(cbind(F1, F2, F3, F4, F5), na.rm=TRUE)


      Right	Wrong   
Men	   199   201   
WomeN  172	 173   


AM = matrix( 
          c(199, 201, 172, 173), # the data elements 
            nrow=2,              # number of rows 
            ncol=2,              # number of columns 
             byrow = TRUE)        # fill matrix by rows 
chisq.test(A) 

t.test(mm,mf,paired=TRUE)

var.test(mm, mf)

# A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis.
#A negative t-value indicates a reversal in the directionality of the effect, which has no bearing on the significance of the difference between groups. Analysis of a negative t-value requires examination of its absolute value in comparison to the value on a table of t-values and degrees of freedom, which quantifies the variability of the final estimated number. If the absolute value of the experimental t-value is smaller than the value found on the degrees of freedom chart, then the means of the two groups can be said to be significantly different.
# The p-value of F-test is p = 0.5903 which is greater than the significance level 0.05. In conclusion, there is no significant difference between the two variances


#ANÁLISE DA INTERPRETAÇÃO DAS FRASES

# GENERO MASCULINO
QM<-select(filter(data, consent == 1, gender == 1),c(VI, VII, VIII, IX, X, XI))
qm6<-table(QM$VI == 1)
qm7<-table(QM$VII == 1)
qm8<-table(QM$VIII == 1)
qm9<-table(QM$IX == 1)
qm10<-table(QM$X == 1)
qm11<-table(QM$XI == 1)

cbind(qm6, qm7, qm8, qm9, qm10, qm11)
MQR<-rowSums(cbind(qm6, qm7, qm8, qm9, qm10, qm11), na.rm=TRUE)

# GENERO FEMININO
QF<-select(filter(data, consent == 1, gender == 2),c(VI, VII, VIII, IX, X, XI))
qm6<-table(QF$VI == 1)
qm7<-table(QF$VII == 1)
qm8<-table(QF$VIII == 1)
qm9<-table(QF$IX == 1)
qm10<-table(QF$X == 1)
qm11<-table(QF$XI == 1)

cbind(qm6, qm7, qm8, qm9, qm10, qm11)
FQR<-rowSums(cbind(qm6, qm7, qm8, qm9, qm10, qm11), na.rm=TRUE)

     Right	Wrong   
Men	   253   269  
WomeN  201	 225   


FB = matrix( 
     c(253, 269, 201, 225), # the data elements 
     nrow=2,              # number of rows 
     ncol=2,              # number of columns 
     byrow = TRUE)        # fill matrix by rows 
chisq.test(B) 

t.test(MQR,FQR,paired=TRUE)

var.test(MQR, FQR)

#######
library(plotrix)
library(ggplot2)

genmasc<-data %>% filter(gender == 1, consent ==1)
agemasc<-genmasc$Age
edumasc<-genmasc$education
ctymasc<-genmasc$country

genfem<-data %>% filter(gender == 2, consent ==1)
agefem<-genfem$Age
edufem<-genfem$education
ctyfem<-genfem$country

write.csv(matrix(as.numeric(agemasc),nrow=1),row.names=FALSE)
write.csv(matrix(as.numeric(agefem),nrow=1),row.names=FALSE)

summary(agemasc)
summary(agefem)
cov(agemasc, agefem) #medida de variabilidade conjunta dessas duas variáveis aleatórias. Quando a covariâncias entre essas variáveis é positiva os dados apresentam tendência positiva na dispersão. Quando o valor da covariância é negativo, o comportamento é análogo, no entanto, os dados apresentam tendências negativas. 
cor(agemasc, agefem) # ASSOCIAÇÃO: Para ρ = 1, tem-se uma correlação perfeita entre as duas variáveis. Se ρ = - 1, há uma correlação perfeita entre as variáveis, no entanto, essa correlação é negativa. Caso ρ = 0, as duas variáveis não dependem linearmente uma da outra.

 t.test(agemasc, agefem) #t-test, used to determine whether the means of two groups are equal to each other. The assumption for the test is that both groups are sampled from normal distributions with equal variances. The null hypothesis is that the two means are equal, and the alternative is that they are not. 

#K = 1+3.3*log(77)
h = (53-15)/7 = 6

itvagemasc<-cut(agemasc,breaks=7)
itvagefem<-cut(agefem,breaks=7)
print(itvagemasc)
print(itvagefem)

agelabels<-c(15,20.4), (20.4,25.9), (25.9,31.3), (31.3,36.7), (36.7,42.1), (42.1,47.6), (47.6,53))

mcol<-color.gradient(c(0,0,0.5,1),c(0,0,0.5,1),c(1,1,0.5,1),7)
fcol<-color.gradient(c(1,1,0.5,1),c(0.5,0.5,0.5,1),c(0.5,0.5,0.5,1),7)
par(mar=pyramid.plot(xyage,xxage,labels=agelabels,main="Gender Age",lxcol=mcol,rxcol=fcol,gap=1,show.values=TRUE))






###
library(plotrix)

x<-c(4.6,4.01,3.71,3.84,4.19,4.10,4.35,3.62,3.25,3.02,2.95,2.44,1.94,1.16,0.98,0.74,0.56)
y<-c(4.25,3.72,3.48,3.69,4.24,4.41,4.61,3.82,3.37,3.2,2.97,2.43,1.94,1.23,1.03,0.78,0.6)

agelabels<-c("0-5","5-10","10-15","15-20","20-25","25-30","30-35",
             "35-40","40-45","45-50","50-55","55-60","60-65","65-70","70-75","75-80","85+")

mcol<-color.gradient(c(0,0,0.5,1),c(0,0,0.5,1),c(1,1,0.5,1),17)
fcol<-color.gradient(c(1,1,0.5,1),c(0.5,0.5,0.5,1),c(0.5,0.5,0.5,1),17)

par(mar=pyramid.plot(x,y,labels=agelabels,lxcol=mcol,rxcol=fcol,show.values=TRUE))
title(sub="Tunisian age pyramid in 2014",cex.sub=1.7)

