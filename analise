library(readxl)
data <- read_excel("C:/Users/smsanda/Pictures/data.xlsx")
View(data)
data<-data18

library(dplyr)

head(data) # Print the first few, or last few, lines of a mdm object
str(data) #check the variables / Get a summary of an object’s structure
summary(data) #Get more detailed information out a model.
dim(data) #check dimesions ( number of row & columns) in data set
ls(data) # List all variables in the environment.
table(is.na(data)) # See counts of missing values
colSums(is.na(data)) # missing value in data exploration stages.
unique(data) #See unique values.

#You can use the loglm( ) function in the MASS package to produce log-linear models. 
library(MASS)
attach(data)

A<-data$gender # Access the values
table(A)
table(A, useNA = "ifany")
hist(table(A))
summary(A)

#uses the cross-classifying factors to build a contingency table of the counts at each combination of factor levels.
B<-data$birthyear
table(B)
table(B, useNA = "ifany")
hist(table(B))
summary(B)

C<-data$education
table(C)
table(C, useNA = "ifany")
hist(table(C))
summary(C)

D<-data$country
table(D)
table(D, useNA = "ifany")
hist(table(D))
summary(D)

#The creation of frequency and contingency tables from categorical variables, along with tests of independence, measures of association, and methods for graphically displaying results.

Generating Frequency Tables
R provides many methods for creating frequency and contingency tables. Three are described below. In the following examples, assume that A, B, and C represent categorical variables.  

mytable <- xtabs(~A+B+C+D, data=data) 
hist(mytable)
summary(mytable) # chi-square test of indepedence

loglm(~A+B+C+D, mytable) #Mutual Independence: A, B, C and D are pairwise independent.

#Análise da origem, educação e idade dos homens
colint <-select(filter(data, gender == 1),c(education, country, birthyear))
# tally() is short-hand for summarise()
colint %>% tally()
head(colint)
summary(colint)
call<-table(colint)
summary(call)

#P=1 - Significa uma correlação perfeita positiva entre as duas variáveis.
#P=-1 - Significa uma correlação negativa perfeita entre as duas variáveis - Isto é, se uma aumenta, a outra sempre diminui.
#P=0  - Significa que as duas variáveis não dependem linearmente uma da outra. No entanto, pode existir uma dependência não linear. Assim, o resultado deve ser investigado por outros meios.

cor(colint)

#Observação sobre os Resultados da Covariância
#Quando covariância é positiva, as duas variáveis analisadas tendem a variar na mesma direção; portanto, se aumenta uma a outra tende a aumentar, ou se uma cai a outra tende a diminuir também. Logo covariância positiva indica que as duas variáveis caminham juntas mediante variações que ocorrerem.
#Quando houver covariância negativa, neste caso há duas variáveis que tendem a variar em direções opostas; ou seja, se há aumento em uma haverá diminuição na outra, ou se uma diminui a outra tende a aumentar. concluímos que a covariância negativa afirma categoricamente que há oposição com relação aos movimentos das variáveis.
#Quanto mais próxima de zero for a covariância obtida aplicando-se a fórmula, menor é a possibilidade de encontrar um comportamento de interdependência linear entre as variáveis.

cov(colint)


#Análise da origem, educação e idade das mulheres
colint2 <-select(filter(data, gender == 2),c(education, country, birthyear))

# tally() is short-hand for summarise()
colint2 %>% tally()
head(colint2)
summary(colint2)
call2<-table(colint2)
summary(call2)

cor(colint2)
cov(colint2)


#Subsetting data
# Select only the variables that you are interested in.

#Desempenho dos homens nas questões de MATEMÁTICA
library(dplyr)

genmascmat<-select(filter(data, consent == 1, gender == 1),c(I, II, III, IV, V))
M1<-table(genmascmat$I ==1)
M2<-table(genmascmat$II ==1)
M3<-table(genmascmat$III ==1)
M4<-table(genmascmat$IV ==1)
M5<-table(genmascmat$V ==1)

cbind(M1, M2, M3, M4, M5)
mm<-rowSums(cbind(M1, M2, M3, M4, M5), na.rm=TRUE)


#Desempenho das mulheres nas questões de MATEMÁTICA
genfemat<-select(filter(data, consent == 1, gender == 2),c(I, II, III, IV, V))
F1<-table(genfemat$I ==1)
F2<-table(genfemat$II ==1)
F3<-table(genfemat$III ==1)
F4<-table(genfemat$IV ==1)
F5<-table(genfemat$V ==1)

cbind(F1, F2, F3, F4, F5)
mf<-rowSums(cbind(F1, F2, F3, F4, F5), na.rm=TRUE)


      Right	Wrong   
Men	   199   201   
WomeN  172	 173   


AM = matrix( 
          c(199, 201, 172, 173), # the data elements 
            nrow=2,              # number of rows 
            ncol=2,              # number of columns 
             byrow = TRUE)        # fill matrix by rows 
chisq.test(A) 

t.test(mm,mf,paired=TRUE)

var.test(mm, mf)

# A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis.
#A negative t-value indicates a reversal in the directionality of the effect, which has no bearing on the significance of the difference between groups. Analysis of a negative t-value requires examination of its absolute value in comparison to the value on a table of t-values and degrees of freedom, which quantifies the variability of the final estimated number. If the absolute value of the experimental t-value is smaller than the value found on the degrees of freedom chart, then the means of the two groups can be said to be significantly different.
# The p-value of F-test is p = 0.5903 which is greater than the significance level 0.05. In conclusion, there is no significant difference between the two variances


#ANÁLISE DA INTERPRETAÇÃO DAS FRASES

# GENERO MASCULINO
QM<-select(filter(data, consent == 1, gender == 1),c(VI, VII, VIII, IX, X, XI))
qm6<-table(QM$VI == 1)
qm7<-table(QM$VII == 1)
qm8<-table(QM$VIII == 1)
qm9<-table(QM$IX == 1)
qm10<-table(QM$X == 1)
qm11<-table(QM$XI == 1)

cbind(qm6, qm7, qm8, qm9, qm10, qm11)
MQR<-rowSums(cbind(qm6, qm7, qm8, qm9, qm10, qm11), na.rm=TRUE)

# GENERO FEMININO
QF<-select(filter(data, consent == 1, gender == 2),c(VI, VII, VIII, IX, X, XI))
qm6<-table(QF$VI == 1)
qm7<-table(QF$VII == 1)
qm8<-table(QF$VIII == 1)
qm9<-table(QF$IX == 1)
qm10<-table(QF$X == 1)
qm11<-table(QF$XI == 1)

cbind(qm6, qm7, qm8, qm9, qm10, qm11)
FQR<-rowSums(cbind(qm6, qm7, qm8, qm9, qm10, qm11), na.rm=TRUE)

     Right	Wrong   
Men	   253   269  
WomeN  201	 225   


FB = matrix( 
     c(253, 269, 201, 225), # the data elements 
     nrow=2,              # number of rows 
     ncol=2,              # number of columns 
     byrow = TRUE)        # fill matrix by rows 
chisq.test(B) 

t.test(MQR,FQR,paired=TRUE)

var.test(MQR, FQR)

# Creating a Graph
attach(colint)
plot(gender, education) 
abline(lm(gender~education))
title("Gender x Education")
    
plot(A, B,         # x variable, y variable
     col = A,                          # colour by species
     main = "A vs B")      # plot title    
     
boxplot(A, B) 
boxplot(A, C)
boxplot(A, D) 
barplot(A, B)
barplot(as.matrix(colint), main="Gender", ylab= "Total",
         beside=TRUE, col=rainbow(5))
dotchart(t(colint), color=c("red","blue","darkgreen", "purple"),
         main="Dotchart for Autos", cex=0.8)
         
# Define cars vector with 5 values
cars <- c(1, 3, 6, 4, 9)

# Define some colors ideal for black & white print
colors <- c("white","grey70","grey90","grey50","black")

# Calculate the percentage for each day, rounded to one 
# decimal place
car_labels <- round(cars/sum(cars) * 100, 1)

# Concatenate a '%' char after each value
car_labels <- paste(car_labels, "%", sep="")

# Create a pie chart with defined heading and custom colors
# and labels
pie(cars, main="Cars", col=colors, labels=car_labels,
   cex=0.8)

# Create a legend at the right   
legend(1.5, 0.5, c("Mon","Tue","Wed","Thu","Fri"), cex=0.8, 
   fill=colors)

