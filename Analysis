#Import Data
data18 <- read.csv("C:/Users/smsanda/Downloads/data18.csv", header=FALSE, sep=";")
View(data18)
str(data18)

data<-data18[complete.cases(data18), ]
str(data)

head(data) # Print the first few, or last few, lines of a mdm object
str(data) #check the variables / Get a summary of an object’s structure
summary(data) #Get more detailed information out a model.
dim(data) #check dimesions ( number of row & columns) in data set
ls(data) # List all variables in the environment.
table(is.na(data)) # See counts of missing values
colSums(is.na(data)) # missing value in data exploration stages.
unique(data) #See unique values.

#Subsetting data
# Select only the variables that you are interested in.

install.packages("dplyr")
library(dplyr)

#filter: the first argument is the data frame; the second argument is the condition by which we want it subsetted. The result is the entire data frame with only the rows we wanted.
#select: the first argument is the data frame; the second argument is the names of the columns we want selected from it. We don’t have to use the names() function, and we don’t even have to use quotation marks. We simply list the column names as objects.


# GENERO MASCULINO

# PERFOMANCE MATEMÁTICA

colint <-select(filter(data, V3 == 1, V24 == 1),c(V17, V18, V19, V20, V21, V22))

# tally() is short-hand for summarise()
colint %>% tally()

# count() is a short-hand for group_by() + tally()
colint %>%
group_by (V17) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint %>%
group_by (V18) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint %>%
group_by (V19) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint %>%
group_by (V20) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint %>%
group_by (V21) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint %>%
group_by (V22) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))


intm <-select(filter(colint, V17 == 1, V18 == 2, V19 == 5, V20 == 1, V21 == 4, V22 == 2 ),c(V17, V18, V19, V20, V21, V22))
View(intm)

M1 <- colint %>%
na.omit %>% 
filter(V24 == 1, V17 == 1, V18 == 2, V19 == 5, V20 == 1, V21 == 4, V22 == 2 )


# PARTE DAS QUOTES PARA HOMENS

QM <-select(filter(data, V3 == 1, V24 == 1),c(V26, V27, V28, V29, V30))

# tally() is short-hand for summarise()
QM %>% tally()

# count() is a short-hand for group_by() + tally()
QM %>%
group_by (V26, V27, V28, V29, V30) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

# GENERO FEMININO
colint2 <-select(filter(data, V3 == 1, V24 == 2),c(V17, V18, V19, V20, V21, V22))

# tally() is short-hand for summarise()
colint2 %>% tally()

# count() is a short-hand for group_by() + tally()
colint2 %>%
group_by (V17) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint2 %>%
group_by (V18) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint2 %>%
group_by (V19) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint2 %>%
group_by (V20) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint2 %>%
group_by (V21) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

colint2 %>%
group_by (V22) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

intf1 <-select(filter(colint2, V17 == 1, V18 == 2, V19 == 5, V20 == 1, V21 == 4, V22 == 2 ),c(V17, V18, V19, V20, V21, V22))

F1 <- colint2 %>%
na.omit %>% 
filter(V17 == 1, V18 == 2, V19 == 5, V20 == 1, V21 == 4, V22 == 2 )

# PARTE DAS QUOTES PARA MULHERES

QF <-select(filter(data, V3 == 1, V24 == 2),c(V26, V27, V28, V29, V30))

# tally() is short-hand for summarise()
QF %>% tally()

# count() is a short-hand for group_by() + tally()
QF %>%
group_by (V26, V27, V28, V29, V30) %>%
summarise (n=n()) %>%
mutate(rel.freq = paste0(round(100 * n/sum(n), 0), "%")) %>%
ungroup() %>%
mutate(row.tot = sum(n))

# CHIQUEST

m17<-table(colint$V17 ==1)
m18<-table(colint$V18 ==2)
m19<-table(colint$V19 ==5)
m20<-table(colint$V20 ==1)
m21<-table(colint$V21 ==4)
m22<-table(colint$V22 ==2)

cbind(m17, m18, m19, m20, m21, m22)
mm<-rowSums(cbind(m17, m18, m19, m20, m21, m22), na.rm=TRUE)

f17<-table(colint2$V17 ==1)
f18<-table(colint2$V18 ==2)
f19<-table(colint2$V19 ==5)
f20<-table(colint2$V20 ==1)
f21<-table(colint2$V21 ==4)
f22<-table(colint2$V22 ==2)

cbind(f17, f18, f19, f20, f21, f22)
mf<-rowSums(cbind(f17, f18, f19, f20, f21, f22), na.rm=TRUE)

       Right	Wrong   TOTAL
Men	   99	  39     138
WomeN  113	  43     156
      

A = matrix( 
          c(99, 39, 113, 53), # the data elements 
            nrow=2,              # number of rows 
            ncol=2,              # number of columns 
             byrow = TRUE)        # fill matrix by rows 
chisq.test(A) 

Now, p < 0,05 is the usual test for dependence. In this case p is greater than 0,05, so we believe the variables are independent (ie not linked together).

No tempo em que não se tinha computadores pararíamos a interpretação nesse ponto, qual seja, se o t calculado é maior que o t tabelado rejeitamos H0 pois apesar de não sabermos qual é a área da curva à direita de 3,01 e à esquerda de -3,01 sabemos que ela é menor que 5% já que para totalizar 5% é necessária a área que vai desde 2,26 até +infinito somada à área que vai de -2,26 até –infinito.

 O valor-p indica a probabilidade de se observar uma diferença tão grande ou maior do que a que foi observada sob
a hipótese nula. Mas se o novo tratamento tiver um efeito de tamanho menor, um estudo com uma pequena amostra pode não ter poder suficiente para detectá-lo.

Outro conceito equivocado é acreditar que, se o valor-p está próximo de 5%, há uma tendência de haver uma diferença entre os grupos. É inadequado interpretar um valor-p de, digamos, 0,06, como uma tendência de diferença. Um valor-p de 0,06 significa que existe
uma probabilidade de 6% de se obter esse resultado por acaso quando o tratamento não tem nenhum efeito
real. Como definimos o nível de significância de 5%, a hipótese nula não deve ser rejeitada.

Na prática, considera-se satisfatório o limite de 5% de probabilidade de erro, não sendo significativas as diferenças que tiverem uma probabilidade acima desse limite.

t.test(mm,mf,paired=TRUE)
var.test(mm, mf)

An F statistic is a value you get when you run an ANOVA test or a regression analysis to find out if the means between two populations are significantly different. It’s similar to a T statistic from a T-Test; A-T test will tell you if a single variable is statistically significant and an F test will tell you if a group of variables are jointly significant.

Why?
The F value should always be used along with the p value in deciding whether your results are significant enough to reject the null hypothesis. If you get a large f value (one that is bigger than the F critical value found in a table), it means something is significant, while a small p value means all your results are significant. The F statistic just compares the joint effect of all the variables together. To put it simply, reject the null hypothesis only if your alpha level is larger than your p value.

CHIQUEST - QUOTES

QM <-select(filter(data, V3 == 1, V24 == 1),c(V26, V27, V28, V29, V30))

# tally() is short-hand for summarise()
QM %>% tally()

qm26<-table(QM$V26 == 5)
qm27<-table(QM$V27 == 5)
qm28<-table(QM$V28 == 5)
qm29<-table(QM$V29 == 5)
qm30<-table(QM$V30 == 5)

cbind(qm26, qm27, qm28, qm29, qm30)
qmm<-rowSums(cbind(qm26, qm27, qm28, qm29, qm30), na.rm=TRUE)


QF <-select(filter(data, V3 == 1, V24 == 2),c(V26, V27, V28, V29, V30))

qm26<-table(QF$V26 == 5)
qm27<-table(QF$V27 == 5)
qm28<-table(QF$V28 == 5)
qm29<-table(QF$V29 == 5)
qm30<-table(QF$V30 == 5)

# tally() is short-hand for summarise()
QF %>% tally()

cbind(qm26, qm27, qm28, qm29, qm30)
qmf<-rowSums(cbind(qm26, qm27, qm28, qm29, qm30), na.rm=TRUE)

      Right	Wrong   TOTAL
Men	 54	  61    
WomeN   68	  62   
      

B = matrix( 
          c(54, 61, 68, 62), # the data elements 
            nrow=2,              # number of rows 
            ncol=2,              # number of columns 
             byrow = TRUE)        # fill matrix by rows 
chisq.test(B) 


 var.test(qmm, qmf)
 
# Tests to see if is significant your sample!
#The F value indicates the ratio of the variance of the group means to that of the pooled within group variance. The larger the F value the greater the relative variance among the group means. The p value tells you the probability of obtaining an F value as extreme or more extreme as the one observed under the assumption that the null hypothesis is true. 

var.test(qmm, qmf)

# T-TEST - Se estivermos usando nível de confiança de 95%, rejeitaríamos a hipótese nula caso:
A probabilidade obtida com o t calculado (-1.1538) é inferior ao "ponto de corte" do p-valor (0.4546), ou
t.test(qmm,qmf,paired=TRUE)

#The p-value is more than the alpha level: p >.05. We cannot reject the null hypothesis that there is difference between means.

















































